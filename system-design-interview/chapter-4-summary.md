처리율 제한 장치의 설계와 구현

#### 기본 개념과 필요성
**처리율 제한 장치란?**
- 클라이언트/서비스의 트래픽 처리율을 제어하는 장치
- DoS 공격 방지, 비용 절감, 서버 과부화 방지 목적

#### 설계 고려사항
**처리율 제한 장치의 위치**
- 클라이언트 측: 보안상 취약하여 비권장
- 서버 측: 
  - 서버 내부 구현
  - API 게이트웨이/미들웨어 사용

#### 주요 알고리즘 비교

**토큰 버킷 알고리즘**
- 동작: 
  1. 지정된 용량의 버킷에 주기적으로 토큰 공급
  2. 요청 처리 시 토큰 소모
  3. 토큰 없으면 요청 거부
- 장점: 구현 쉽고 메모리 효율적
- 단점: 파라미터 튜닝 어려움

**누출 버킷 알고리즘**
- 동작:
  1. 큐로 구현
  2. 요청은 큐에 추가
  3. 일정 속도로 요청 처리
- 장점: 안정적인 출력
- 단점: 버스트 트래픽 처리 어려움

**고정 윈도 카운터**
- 동작:
  1. 시간을 고정 윈도로 분할
  2. 각 윈도에서 요청 수 카운트
  3. 임계치 초과시 거부
- 장점: 단순하고 메모리 효율적
- 단점: 경계 부근 트래픽 처리 부정확

**이동 윈도 카운터**
- 동작: 현재 윈도와 이전 윈도의 가중 평균으로 처리
- 장점: 버스트 트래픽 대응 가능, 메모리 효율적
- 단점: 정확도가 다소 떨어짐

#### 처리율 제한 장치의 기본 아키텍처 및 동작 원리

**기본 아키텍처**
- 각 대상별로 카운터를 두어 요청 추적
- 임계치 초과시 요청 거부하는 단순한 방식

**동작 흐름**
1. 클라이언트 → 처리율 제한 미들웨어로 요청 전송
2. 미들웨어에서 캐시된 규칙과 카운터 확인
3. 처리 결정:
  - 한도 미달시: API 서버로 전달 + 카운터 증가
  - 한도 초과시: 429 에러 반환 또는 큐잉

**주요 컴포넌트**
- 규칙 저장소: 디스크에 저장
- 캐시: 규칙과 카운터 저장
- 미들웨어: 제한 로직 처리
- API 서버: 실제 요청 처리

